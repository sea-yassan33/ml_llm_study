# 【大規模言語モデル(LLM)について】

## 1. 大規模言語モデル(LLM)とは
- 大規模言語モデル(LLM：Large Language Model）は、自然言語処理の分野で使用される大規模なニューラルネットワークモデルです。
- 機械学習の一種であり、膨大なテキストデータを学習し、自然言語の理解や生成を行います。
- インターネット上の文章、論文、書籍コードなど膨大なテキストを事前学習し、数十億〜数千億 ものパラメータを持つ巨大なモデルです。
- 特定のタスク向けに大量のラベル付きデータを集めなくても、ある程度汎用的に使用できるのが特徴です。
- プロンプト（指示文） を工夫すれば、モデル内部で ベクトル化を行い、翻訳・要約・生成などを柔軟に行ってくれれます。

## 2.LLMの主なサービス

### [言語生成AI]
- **ChatGPT(OpenAI)**
  - テキスト・音声・画像を統合的に扱える真のマルチモーダルAIとして、様々なタスクに対応可能です。
- **Bard(Google)**
  - Googleが開発した対話型AIサービスです。人間との会話のような自然なやり取りが可能な対話型AIに、Googleが誇る検索サービスを連携しており、チャットで質問をするだけで、AIがビッグデータから自然かつ正確な回答を出力してくれます。
- **Bing Chat(Microsoft)**
  - Microsoft Bing検索エンジンに統合されたチャットモードで、会話形式で情報を得たり、質問に答えてもらったり、会話を楽しむことができるAIチャットツールです。
- **Copilot(Microsoft)**
  - Microsoft Office製品（Word、Excel、PowerPointなど）に統合されたAIアシスタントで、文書作成やデータ分析を支援します。
- **bolt.new(StackBlitz)**
  - テキストのみでフルスタックアプリケーションを開発できるAIツールです。

### [動画生成AI]
- **Stable Diffusion(CompVis group)**
  - テキストから画像を生成するAIモデルで、特にアートやデザインの分野で注目されています。
- **Midjourney(米サンフランシスコのAI研究所)**
  - テキストによる指示（プロンプト）から高品質な画像を生成できるAIツールです。Discordというチャットアプリ上で動作し、専門知識がなくても簡単に利用できます。
- **Adobe Firefly(Adobe)**
  - Adobeが開発した画像生成AIで、ユーザーが入力したテキストに基づいて画像を生成します。Adobeの他の製品と統合されており、クリエイティブな作業を支援します。
- **Gen-2(Runway)**
  - 動画編集の作業を効率化したい企業や、クリエイターが利用しているサービスです。

### [音声生成AI]
- **MusicGen(Meta)**
  - 文章や既存のメロディーをもとに最大15秒の音楽を生成するAIです。
- **Synthesizer V(Dreamtonics)**
  - 歌詞やメロディを簡単に入力して、ボーカルと新しい曲のアイデアを書き出します。
- **so-vits-svc(so-develop-team)**
  - 音声変換のためのAIモデルで、特定の声質を別の声質に変換することができます。

## 3. LLM(クライド型)とローカルLLM

### [ローカルLLM]
- LLMは通常、クラウド上で動作し、大量の計算資源を必要としますが、ローカルLLMは個人のPCやサーバー上で動かすLLMです。
- 個別ニーズに応じた柔軟性を持つだけでなく、データセキュリティの向上や依存度の低減といったメリットがあります。

### [LLM(クライド型)とローカルLLMの違い]

|観点|LLM(クラウド型)|ローカルLLM|
|:----|:----|:----|
|運用環境|クラウドサーバー上で動作し、インターネットを通じて利用|個人のPCや自社サーバで動作し、オフライン上でLLMを利用|
|接続要件|インターネット接続が必要|インターネット接続が不要|
|コスト|使用量に応じた従量課金|GPUを搭載したPCまたはサーバの調達コスト<br>電気代・ハードウェアの維持コスト|
|データ処理|入力データがクラウド上のサーバに送信され、クラウドサーバ内で処理が行われる|データはローカル環境で処理され、外部に送信されない|
|プライバシー|LLMを提供しているクラウドサービスの大半が英語圏の為、セキュリティ設定により漏洩のリスクが高い|データがローカル環境内で完結するため、漏洩のリスクが低い|
|性能と応答速度|高性能なサーバを利用するため、応答速度が速く、大規模モデルの利用が可能|ハードウェアの性能に依存するため、大規模モデルでは応答速度が低下する場合がある|

### [ローカルLLM一覧(2025年1月時点)](https://www.ask-corp.jp/biz/column/local-large-language-models.html)

|モデル|開発元|特徴|
|:----|:----|:----|
|[Mistral-Nemo-Japanese-Instruct-2408](https://huggingface.co/cyberagent/Mistral-Nemo-Japanese-Instruct-2408)|サイバーエージェント<br>（基盤：Mistral、NVIDIA）|日本語特化のチューニングが施された高性能モデル。大規模コンテキストウィンドウ（最大128,000トークン）対応。|
|[Llama-3-ELYZA-JP-8B](https://huggingface.co/elyza/Llama-3-ELYZA-JP-8B)|ELYZA<br>（基盤：Meta Llama 3）|	日本語特化のファインチューニング済み。軽量ながら高い日本語処理能力を発揮。|
|[Llama-3.1-Swallow-8B-Instruct-v0.2](https://huggingface.co/tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2)|東京工業大学＋産業技術総合研究所<br>（基盤：Meta Llama 3.1）|日本語対応強化。長文コンテキスト処理（最大32,768トークン）。指示に基づいた応答生成が可能。|
|[Qwen2.5-7B-Instruct](https://huggingface.co/Qwen/Qwen2.5-7B-Instruct)|Alibaba|日本語対応。長文処理に強く、セキュアなローカル環境で動作可能。ただし、中国語混在の可能性あり。|
|[Gemma-2-2b-jpn-it](https://huggingface.co/google/gemma-2-2b-jpn-it)|Google|日本語特化の軽量モデル。2Bパラメータで効率的に動作。小規模なローカル環境で利用可能。|

## 4. Hugging FaceとLLM
- [Hugging Face](https://huggingface.co/)は、自然言語処理のためのオープンソースライブラリであり、LLMを簡単に利用できるプラットフォームです。
- 「AI分野のGitHub」とも称され、数多くのLLMモデルが公開されています。
- 学習済みのモデルやデータセットを使用することができ、AI研究や開発に役立てることができます。
- 例えば、音声データからテキストデータに変換するモデルが公開されいます。応用することで議事録作成AIアプリの作成が可能になります。

### [実装例]音声データからテキストデータへ変換
- [【音声から文字おこし】HuggingFaceのオープンソースを用いて実装](https://qiita.com/sea_news_yass/items/209e3dd7754f883110de)

## 5.DifyとOllama

### [Dify](https://dify.ai/jp)
- Difyは、LLM(大規模言語モデル)を活用したAIアプリケーションです。
- ノーコードでAIアプリケーションを開発ができます。
- GitHub上で公開されているLLMを利用して、独自のAIアプリケーションを構築することができます。

### [Ollama](https://ollama.com/)
- Ollamaは、ローカル環境でLLM(大規模言語モデル)を起動および実行をサポートするツールです。

### [DifyとOllamaを使ってローカルLLM環境構築]
- DifyとOllamaを使用し、ローカル環境でLLMを動かす事が可能になります。
- AIアプリケーション開発やLLMを用いたプロダクトを提供する事が可能になります。
- [ローカルLLM環境構築方法](https://qiita.com/sea_news_yass/items/0cdde73d539873bfa29c)


## 6.機械学習とLLMの違い

- 機械学習は、特徴量を定義し、データの中で規則性を抽出して予測や分類を行うのに対し、LLMは膨大なテキストデータから自動的に言語のパターンを学習します。
- 機械学習は高い精度が求められるサービスに利用されます。
- 一方、LLMは大量のテキストを基に汎用的な回答や生成が求められるサービスに利用されます。

|観点|機械学習|LLM|
|:----|:----|:----|
|データ入力|数値・カテゴリーデータ・画像・音声|自然言語（テキスト）|
|スケール|小規模～中規模<br>(数千～数百万パラメータ)|大規模<br>(数十億～数千億パラメータ)|
|学習方法|教師あり・教師なし・強化学習|事前学習＋微調整<br>（ファインチューニング）<br>ニューラルネットワーク|
|使用資源|CPU・小型GPUで可能|高性能GPU・TPU、大量の計算資源|
|用途|医療画像診断・認証システムなどの機密な予測・制御が必要なサービス|汎用的な回答・生成を必要とするサービス|

<hr>

｜[<<機械学習について](./1_機械学習について.md) ｜[学習ロードマップ>>](./3_学習ロードマップについて.md)｜